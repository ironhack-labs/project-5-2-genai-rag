{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "Direct targeting of mitochondria by cisplatin leads\n",
      "to cytotoxicity in zebraﬁsh lateral-line hair cells\n",
      "David S. Lee,\n",
      "Angela Schrader,\n",
      "Jiaoxia Zou, Wee\n",
      "Han Ang, Mark E.\n",
      "Warchol, Lavinia\n",
      "Sheets\n",
      "sheetsl@wustl.edu\n",
      "Highlights\n",
      "Hair cells with more\n",
      "cumulative metabolic\n",
      "activity are suscep\n",
      "\n",
      "Document 2 (First 300 characters):\n",
      " \n",
      " \n",
      "1 \n",
      " \n",
      "Driving forces for condensation of synapsin are governed by \n",
      "sequence-encoded molecular grammars \n",
      " \n",
      "Christian Hoffmann a,1, Kiersten M. Ruff b,1, Irina A. Edu c, Min Kyung Shinn b, Johannes V. Tromm \n",
      "a, Matthew R. King b, Avnika Pant b, Hannes Ausserwöger c, Jennifer R. Morgan d, Tuomas P. \n",
      "\n",
      "Document 3 (First 300 characters):\n",
      "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/383108685\n",
      "Advancements of Nano-biotechnology in Public Health Sector: Beneﬁts and\n",
      "Challenges\n",
      "Article · August 2024\n",
      "DOI: 10.2174/0122106812316402240808101033\n",
      "CITATIONS\n",
      "0\n",
      "READS\n",
      "72\n",
      "5 authors, i\n",
      "\n",
      "Document 4 (First 300 characters):\n",
      "Citation: Kim, M.; Hong, S.\n",
      "Integrating Artificial Intelligence to\n",
      "Biomedical Science: New Applications\n",
      "for Innovative Stem Cell Research and\n",
      "Drug Development. Technologies 2024,\n",
      "12, 95. https://doi.org/10.3390/\n",
      "technologies12070095\n",
      "Academic Editors: R. Simon Sherratt,\n",
      "Juvenal Rodriguez-Resendiz, Ge\n",
      "\n",
      "Document 5 (First 300 characters):\n",
      "Vol.:(0123456789)\n",
      " Discover Materials            (2024) 4:53  \n",
      "| https://doi.org/10.1007/s43939-024-00115-4\n",
      "Discover Materials\n",
      "Review\n",
      "Advancements in 3D printing techniques for biomedical applications: \n",
      "a comprehensive review of materials consideration, post processing, \n",
      "applications, and challenges\n",
      "\n",
      "Document 6 (First 300 characters):\n",
      "Channel-facilitated transport under resetting dynamics\n",
      "Suvam Pal∗\n",
      "Physics and Applied Mathematics Unit, Indian Statistical Institute, 203 B.T. Road Kolkata, India\n",
      "Denis Boyer†\n",
      "Instituto de F´ısica, Universidad Nacional Aut´onoma de M´exico, Ciudad de M´exico C.P. 04510 M´exico.\n",
      "Leonardo Dagdug‡\n",
      "Phys\n",
      "\n",
      "Document 7 (First 300 characters):\n",
      "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/380855472\n",
      "Modeling of nanoblood ﬂow in an artery in presence of eco-friendly and\n",
      "biocompatible hybrid nanoparticles Modeling of nanoblood ﬂow in an artery\n",
      "in presence of eco-friendly and b..\n",
      "\n",
      "Document 8 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "FSTL-1 loaded 3D bioprinted vascular patch\n",
      "regenerates the ischemic heart tissue\n",
      "Boeun Hwang,\n",
      "Lauren Korsnick,\n",
      "Ming Shen, ...,\n",
      "Mostafa Abdalla,\n",
      "Holly Bauser-\n",
      "Heaton, Vahid\n",
      "Serpooshan\n",
      "vahid.serpooshan@bme.\n",
      "gatech.edu\n",
      "Highlights\n",
      "A vascular cardiac patch is\n",
      "biofabricated through\n",
      "mold-c\n",
      "\n",
      "Document 9 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "Optimized in vivo multispectral bioluminescent\n",
      "imaging of tumor biology using engineered BRET\n",
      "reporters\n",
      "Bryan Labra, Kshitij\n",
      "Parag-Sharma,\n",
      "John J. Powers, ...,\n",
      "Caroline K.\n",
      "Brennan, Jennifer\n",
      "A. Prescher,\n",
      "Antonio L. Amelio\n",
      "antonio.amelio@mofﬁtt.org\n",
      "Highlights\n",
      "Library of epitope-tagged\n",
      "\n",
      "Document 10 (First 300 characters):\n",
      "Research Article\n",
      "Vol. 32, No. 19 / 9 Sep 2024 / Optics Express 33628\n",
      "Enhanced denoising for weak signal\n",
      "preservation in structured illumination\n",
      "microscopy\n",
      "ZHENGAN FU,1,† JUNKANG DAI,1,† BOWEN LIU,1 ZITONG JIN,1\n",
      "JINJIN ZHENG,1 HUAIAN CHEN,1,2 AND YI JIN1,3\n",
      "1Department of Precision Machinery and Preci\n",
      "\n",
      "Document 11 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "Branch-speciﬁc clustered parallel ﬁber input\n",
      "controls dendritic computation in Purkinje cells\n",
      "Gabriela Cirtala,\n",
      "Erik De Schutter\n",
      "gabriela.cirtala@gmail.com\n",
      "Highlights\n",
      "We propose a\n",
      "heterogeneous ion channel\n",
      "density Purkinje cell model\n",
      "Branch-speciﬁc\n",
      "conductance densities\n",
      "compensate f\n",
      "\n",
      "Document 12 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "An ensemble deep learning model for predicting\n",
      "minimum inhibitory concentrations of antimicrobial\n",
      "peptides against pathogenic bacteria\n",
      "Chia-Ru Chung,\n",
      "Chung-Yu Chien,\n",
      "Yun Tang, ...,\n",
      "Tzong-Yi Lee,\n",
      "Chen Bai, Jorng-\n",
      "Tzong Horng\n",
      "baichen@cuhk.edu.cn (C.B.)\n",
      "horng@db.csie.ncu.edu.tw\n",
      "(J.-T.H\n",
      "\n",
      "Document 13 (First 300 characters):\n",
      "PRX LIFE 2, 043001 (2024)\n",
      "Conditioned Protein Structure Prediction\n",
      "Tengyu Xie\n",
      ",* Zilin Song\n",
      ",*,† and Jing Huang\n",
      "‡\n",
      "School of Life Sciences, Westlake University, Hangzhou, Zhejiang 310024, China\n",
      "(Received 18 February 2024; accepted 13 September 2024; published 4 October 2024)\n",
      "Deep-learning-based prote\n",
      "\n",
      "Document 14 (First 300 characters):\n",
      "Main Manuscript for  \n",
      " \n",
      "Engineered bacteria that self-assemble “bioglass” polysilicate coatings \n",
      "display enhanced light focusing  \n",
      " \n",
      "5 \n",
      "Lynn M. Sidor1, Michelle M. Beaulieu2, Ilia Rasskazov3,4, B. Cansu Acarturk5, Jie Ren5, Lycka \n",
      "Kamoen6,7, María Vázquez Vitali6, P. Scott Carney3, Greg R. Schmidt3,\n",
      "\n",
      "Document 15 (First 300 characters):\n",
      "Citation: Cao, M.; Zhang, X. DNA\n",
      "Adductomics: A Narrative Review of\n",
      "Its Development, Applications, and\n",
      "Future. Biomolecules 2024, 14, 1173.\n",
      "https://doi.org/10.3390/\n",
      "biom14091173\n",
      "Academic Editor: Il Je Yu\n",
      "Received: 18 July 2024\n",
      "Revised: 24 August 2024\n",
      "Accepted: 10 September 2024\n",
      "Published: 19 Septemb\n",
      "\n",
      "Document 16 (First 300 characters):\n",
      "Hao et al. Light: Science & Applications   (2024) 13:195 \n",
      "Ofﬁcial journal of the CIOMP 2047-7538\n",
      "https://doi.org/10.1038/s41377-024-01536-9\n",
      "www.nature.com/lsa\n",
      "A R T I C L E\n",
      "O p e n A c c e s s\n",
      "Single 5-nm quantum dot detection via\n",
      "microtoroid optical resonator photothermal\n",
      "microscopy\n",
      "Shuang Hao1, Sa\n",
      "\n",
      "Document 17 (First 300 characters):\n",
      "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/375539201\n",
      "Seeing the Supracolloidal Assemblies in 3D: Unraveling High-Resolution\n",
      "Structures Using Electron Tomography\n",
      "Article  in  ACS Materials Au · May 2024\n",
      "DOI: 10.1021/acsmaterialsau.3c0\n",
      "\n",
      "Document 18 (First 300 characters):\n",
      "iScience\n",
      "Article\n",
      "Rapid and speciﬁc detection of nanoparticles and\n",
      "viruses one at a time using microﬂuidic laminar ﬂow\n",
      "and confocal ﬂuorescence microscopy\n",
      "2. Measurement \n",
      "1. Incubation \n",
      "Correlated signals\n",
      "Laminar flow\n",
      "Fluorescent Microscope \n",
      "Sample\n",
      "Virus \n",
      "Laser beam\n",
      "Fluorescent antibody\n",
      "Free fluoresc\n",
      "\n",
      "Document 19 (First 300 characters):\n",
      "Article\n",
      "https://doi.org/10.1038/s41467-024-53030-w\n",
      "NanoPlex: a universal strategy for\n",
      "ﬂuorescence microscopy multiplexing using\n",
      "nanobodies with erasable signals\n",
      "Nikolaos Mougios1,2, Elena R. Cotroneo3, Nils Imse3, Jonas Setzke\n",
      "2,\n",
      "Silvio O. Rizzoli\n",
      "1,4, Nadja A. Simeth\n",
      "3,4, Roman Tsukanov\n",
      "5 &\n",
      "Felipe \n",
      "\n",
      "Document 20 (First 300 characters):\n",
      "Review\n",
      "Large language model to multimodal large language\n",
      "model: A journey to shape the biological\n",
      "macromolecules to biological sciences and\n",
      "medicine\n",
      "Manojit Bhattacharya,1,5 Soumen Pal,2,5 Srijan Chatterjee,3,5 Sang-Soo Lee,3 and Chiranjib Chakraborty4,5\n",
      "1Department of Zoology, Fakir Mohan Universit\n",
      "\n",
      "Extracted text from 20 PDF files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page_num in range(pdf.page_count):\n",
    "            page = pdf[page_num]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Path to your folder containing PDFs\n",
    "folder_path = \"data\"\n",
    "\n",
    "# List all PDF files in the folder\n",
    "pdf_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.pdf')]\n",
    "\n",
    "# Extract text from each PDF and store in a list\n",
    "documents = [extract_text_from_pdf(pdf_path) for pdf_path in pdf_files]\n",
    "\n",
    "# Display some text snippets for verification\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"\\nDocument {i} (First 300 characters):\")\n",
    "    print(doc[:300])  # Show a snippet of each document\n",
    "\n",
    "print(f\"\\nExtracted text from {len(documents)} PDF files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 362 documents\n",
      "Created 2039 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/171kbmdd6xz472m_y73h9fb40000gn/T/ipykernel_13196/183302861.py:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/Users/julianuss/IH/venv_IH/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/var/folders/gs/171kbmdd6xz472m_y73h9fb40000gn/T/ipykernel_13196/183302861.py:47: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store\n",
      "Setup QA chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/171kbmdd6xz472m_y73h9fb40000gn/T/ipykernel_13196/183302861.py:79: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Wiener filtering and OPIE are both techniques used in noise reduction applications, including illumination microscopy. However, they differ in their approach and assumptions made about the noise structure.\n",
      "\n",
      "Wiener filtering is a traditional method that incorporates the out-of-focus noise term into the random noise term. In other words, it assumes that the noise in the image is a combination of both additive white Gaussian noise (AWGN) and out-of-focus noise. The Wiener filter estimates the noise covariance matrix using the AWGN term and then applies a covariance-based filtering method to reduce the noise.\n",
      "\n",
      "On the other hand, OPIE assumes that the noise in the image is primarily due to the out-of-focus signal and makes no assumptions about the AWGN term. Instead, it uses the information from the other layers in the sample space (Z1 and Z−1) to enhance the weak signal in the center layerZ0. OPIE performs 3D Wiener filtering under the assumption of a thin sample, which means that the plane fluorescence intensity distribution far from the focal plane is zero. This allows for the expansion of equation (2) and the separation of the out-of-focus noise into different layers.\n",
      "\n",
      "In summary, Wiener filtering assumes a mixed noise structure with both AWGN and out-of-focus noise, while OPIE assumes that the noise is primarily due to out-of-focus signal and uses the information from other layers to enhance the weak signal in the center layer.\n",
      "\n",
      "Response: There are several methods for DNA adductomics screening, depending on the scan modes and instrumental configurations. These include:\n",
      "\n",
      "1. Pseudo-CNL screening method: This is the simplest method established by the Matsuda laboratory in their study of pioneered DNA adductomics. The method uses the MRM scan mode and covers a wide m/z range, such as from 228.8 to 602.8.\n",
      "2. Full scan: Other laboratories have also established their own versions of the DNA adductomic screening methods based on the same principle of the neutral loss of dR and nucleobases but used different scanning modes and/or instrumental configurations. For example, the Vanhaecke laboratory established a method using the full scan, SIM, and SIM-MS/MS modes.\n",
      "3. SIM (Selective Ion Monitoring) mode: This method is also used for DNA adductomics screening, which selectively monitors specific ions in a mixture without interference from other ions.\n",
      "4. SIM-MS/MS (Selected Reaction Monitoring-Mass Spectrometry): This method combines the selective monitoring of ions in SIM mode with MS/MS technology, which provides higher sensitivity and accuracy for detecting and quantifying DNA adducts.\n",
      "\n",
      "It is important to note that these methods are not mutually exclusive, and different laboratories may use a combination of these approaches depending on their specific research goals and instrumentation.\n",
      "\n",
      "Response: I'm not able to provide an answer to your question as I'm just an AI and do not have access to the specific context you provided. The copyright holder for the preprint is not explicitly stated in the given text, so I cannot determine who the copyright holder is. If you have any other questions or if there is anything else I can help with, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# online version\n",
    "# Required installations:\n",
    "# pip install langchain chromadb pypdf sentence-transformers ollama\n",
    "# ollama pull llama2\n",
    "# example question: what methods can we use for DNA adductomics screening? \n",
    "\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "def load_pdfs(directory):\n",
    "   \"\"\"Load PDF files from directory\"\"\"\n",
    "   loader = DirectoryLoader(directory, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "   documents = loader.load()\n",
    "   return documents\n",
    "\n",
    "\n",
    "def split_documents(documents):\n",
    "   \"\"\"Split documents into chunks\"\"\"\n",
    "   text_splitter = RecursiveCharacterTextSplitter(\n",
    "       chunk_size=1000,\n",
    "       chunk_overlap=200\n",
    "   )\n",
    "   chunks = text_splitter.split_documents(documents)\n",
    "   return chunks\n",
    "\n",
    "\n",
    "def create_vector_store(chunks):\n",
    "   \"\"\"Create vector store from document chunks\"\"\"\n",
    "   embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "   vectorstore = Chroma.from_documents(\n",
    "       documents=chunks,\n",
    "       embedding=embeddings,\n",
    "       persist_directory=\"db\"\n",
    "   )\n",
    "   return vectorstore\n",
    "\n",
    "\n",
    "def setup_qa_chain(vectorstore):\n",
    "   \"\"\"Setup QA chain with local LLM\"\"\"\n",
    "   llm = Ollama(model=\"llama2\")\n",
    "   qa_chain = RetrievalQA.from_chain_type(\n",
    "       llm=llm,\n",
    "       chain_type=\"stuff\",\n",
    "       retriever=vectorstore.as_retriever()\n",
    "   )\n",
    "   return qa_chain\n",
    "\n",
    "\n",
    "def main():\n",
    "   # Load documents\n",
    "   documents = load_pdfs(\"data\")\n",
    "   print(f\"Loaded {len(documents)} documents\")\n",
    "  \n",
    "   # Split into chunks\n",
    "   chunks = split_documents(documents)\n",
    "   print(f\"Created {len(chunks)} chunks\")\n",
    "  \n",
    "   # Create vector store\n",
    "   vectorstore = create_vector_store(chunks)\n",
    "   print(\"Created vector store\")\n",
    "  \n",
    "   # Setup QA chain\n",
    "   qa_chain = setup_qa_chain(vectorstore)\n",
    "   print(\"Setup QA chain\")\n",
    "  \n",
    "   # Interactive query loop\n",
    "   while True:\n",
    "       query = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
    "       if query.lower() == 'quit':\n",
    "           break\n",
    "      \n",
    "       response = qa_chain.run(query)\n",
    "       print(\"\\nResponse:\", response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting document processing...\n",
      "Loaded 362 documents\n",
      "Created 3593 chunks\n",
      "Created vector store\n",
      "Setup complete in 53.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# offline version\n",
    "# test question: what methods can we use for DNS adductomics screening?\n",
    "# no chroma db meaning everytime you run the code, it 'trains' the data from the beginning.\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "import time\n",
    "\n",
    "\n",
    "def load_pdfs(directory):\n",
    "   loader = DirectoryLoader(directory, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "   documents = loader.load()\n",
    "   return documents\n",
    "\n",
    "\n",
    "def split_documents(documents):\n",
    "   text_splitter = RecursiveCharacterTextSplitter(\n",
    "       chunk_size=500,\n",
    "       chunk_overlap=50\n",
    "   )\n",
    "   chunks = text_splitter.split_documents(documents)\n",
    "   return chunks\n",
    "\n",
    "\n",
    "def create_vector_store(chunks):\n",
    "   model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "   model_kwargs = {'device': 'cpu'}\n",
    "   encode_kwargs = {'normalize_embeddings': False}\n",
    "  \n",
    "   embeddings = HuggingFaceEmbeddings(\n",
    "       model_name=model_name,\n",
    "       model_kwargs=model_kwargs,\n",
    "       encode_kwargs=encode_kwargs,\n",
    "       cache_folder=\"./models\"\n",
    "   )\n",
    "  \n",
    "   vectorstore = Chroma.from_documents(\n",
    "       documents=chunks,\n",
    "       embedding=embeddings,\n",
    "       persist_directory=\"db\"\n",
    "   )\n",
    "   return vectorstore\n",
    "\n",
    "\n",
    "def setup_qa_chain(vectorstore):\n",
    "   llm = Ollama(model=\"llama2:7b\", temperature=0)\n",
    "   qa_chain = RetrievalQA.from_chain_type(\n",
    "       llm=llm,\n",
    "       chain_type=\"stuff\",\n",
    "       retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "   )\n",
    "   return qa_chain\n",
    "\n",
    "\n",
    "def process_query(qa_chain, query):\n",
    "   start_time = time.time()\n",
    "   response = qa_chain.run(query)\n",
    "   duration = time.time() - start_time\n",
    "   return response, duration\n",
    "\n",
    "\n",
    "def main():\n",
    "   os.makedirs(\"models\", exist_ok=True)\n",
    "  \n",
    "   start_time = time.time()\n",
    "   print(\"Starting document processing...\")\n",
    "  \n",
    "   documents = load_pdfs(\"data\")\n",
    "   print(f\"Loaded {len(documents)} documents\")\n",
    "  \n",
    "   chunks = split_documents(documents)\n",
    "   print(f\"Created {len(chunks)} chunks\")\n",
    "  \n",
    "   vectorstore = create_vector_store(chunks)\n",
    "   print(\"Created vector store\")\n",
    "  \n",
    "   qa_chain = setup_qa_chain(vectorstore)\n",
    "   print(f\"Setup complete in {time.time() - start_time:.2f} seconds\")\n",
    "  \n",
    "   while True:\n",
    "       query = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
    "       if query.lower() == 'quit':\n",
    "           break\n",
    "      \n",
    "       response, duration = process_query(qa_chain, query)\n",
    "       print(f\"\\nResponse ({duration:.2f} seconds):\")\n",
    "       print(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n",
    "\n",
    "quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (0.3.5)\n",
      "Requirement already satisfied: transformers in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (4.46.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (3.2.1)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.13 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (0.3.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: filelock in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.13->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.13->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/julianuss/IH/venv_IH/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Downloading faiss_cpu-1.9.0-cp311-cp311-macosx_11_0_arm64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain transformers sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from PIL import Image\n",
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_IH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
